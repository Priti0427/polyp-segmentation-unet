{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# UNet for Polyp Segmentation in Colonoscopy Images\n",
        "\n",
        "## Deep Learning Final Project\n",
        "\n",
        "**Problem**: Colorectal cancer is the 3rd most common cancer worldwide. During colonoscopy, 14-30% of polyps are missed by physicians. Automated polyp segmentation can assist doctors in identifying polyp boundaries accurately.\n",
        "\n",
        "**Dataset**: Kvasir-SEG (1,000 polyp images with pixel-wise segmentation masks)\n",
        "\n",
        "**Architecture**: UNet (Encoder-Decoder with Skip Connections)\n",
        "\n",
        "**Experiments**:\n",
        "1. Shallow UNet (2 blocks) vs Standard UNet (4 blocks)\n",
        "2. UNet WITH vs WITHOUT skip connections\n",
        "3. Different loss functions (BCE, Dice, Combined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages (for Google Colab)\n",
        "# !pip install torch torchvision matplotlib numpy pillow tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download Kvasir-SEG Dataset\n",
        "\n",
        "The Kvasir-SEG dataset contains 1,000 polyp images with corresponding segmentation masks. Each image shows a polyp during colonoscopy, and the mask indicates the exact polyp region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Download and extract Kvasir-SEG dataset\n",
        "import ssl\n",
        "import certifi\n",
        "\n",
        "DATA_URL = \"https://datasets.simula.no/downloads/kvasir-seg.zip\"\n",
        "DATA_DIR = \"data\"\n",
        "DATASET_DIR = os.path.join(DATA_DIR, \"Kvasir-SEG\")\n",
        "\n",
        "def download_dataset():\n",
        "    \"\"\"Download Kvasir-SEG dataset if not already present.\"\"\"\n",
        "    if os.path.exists(DATASET_DIR):\n",
        "        print(\"Dataset already exists!\")\n",
        "        return\n",
        "    \n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "    zip_path = os.path.join(DATA_DIR, \"kvasir-seg.zip\")\n",
        "    \n",
        "    print(\"Downloading Kvasir-SEG dataset...\")\n",
        "    \n",
        "    # Create SSL context to handle certificate issues\n",
        "    try:\n",
        "        # First try with certifi certificates\n",
        "        ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
        "        urllib.request.urlretrieve(DATA_URL, zip_path)\n",
        "    except:\n",
        "        # If that fails, try with unverified context (less secure but works)\n",
        "        ssl_context = ssl.create_default_context()\n",
        "        ssl_context.check_hostname = False\n",
        "        ssl_context.verify_mode = ssl.CERT_NONE\n",
        "        \n",
        "        # Use urlopen with custom context\n",
        "        import shutil\n",
        "        with urllib.request.urlopen(DATA_URL, context=ssl_context) as response:\n",
        "            with open(zip_path, 'wb') as out_file:\n",
        "                shutil.copyfileobj(response, out_file)\n",
        "    \n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "    \n",
        "    os.remove(zip_path)\n",
        "    print(\"Dataset ready!\")\n",
        "\n",
        "download_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Class\n",
        "\n",
        "We create a custom PyTorch Dataset that:\n",
        "- Loads images and their corresponding masks\n",
        "- Resizes to 256x256 for efficient training\n",
        "- Applies data augmentation (horizontal flip, vertical flip, rotation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class PolypDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for Kvasir-SEG polyp segmentation.\n",
        "    \n",
        "    Args:\n",
        "        image_dir: Path to images folder\n",
        "        mask_dir: Path to masks folder\n",
        "        img_size: Target size for resizing (default 256)\n",
        "        augment: Whether to apply data augmentation\n",
        "    \"\"\"\n",
        "    def __init__(self, image_dir, mask_dir, img_size=256, augment=False):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        \n",
        "        # Get list of image files\n",
        "        self.images = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Load image and mask\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, img_name)\n",
        "        \n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('L')  # Grayscale mask\n",
        "        \n",
        "        # Resize\n",
        "        image = TF.resize(image, (self.img_size, self.img_size))\n",
        "        mask = TF.resize(mask, (self.img_size, self.img_size))\n",
        "        \n",
        "        # Data augmentation (applied to both image and mask)\n",
        "        if self.augment:\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.hflip(image)\n",
        "                mask = TF.hflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                image = TF.vflip(image)\n",
        "                mask = TF.vflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                angle = random.randint(-30, 30)\n",
        "                image = TF.rotate(image, angle)\n",
        "                mask = TF.rotate(mask, angle)\n",
        "        \n",
        "        # Convert to tensors\n",
        "        image = TF.to_tensor(image)  # [3, H, W], values in [0, 1]\n",
        "        mask = TF.to_tensor(mask)    # [1, H, W], values in [0, 1]\n",
        "        \n",
        "        # Binarize mask (threshold at 0.5)\n",
        "        mask = (mask > 0.5).float()\n",
        "        \n",
        "        return image, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create dataset and data loaders\n",
        "IMAGE_DIR = os.path.join(DATASET_DIR, \"images\")\n",
        "MASK_DIR = os.path.join(DATASET_DIR, \"masks\")\n",
        "\n",
        "# Full dataset (without augmentation for splitting)\n",
        "full_dataset = PolypDataset(IMAGE_DIR, MASK_DIR, img_size=256, augment=False)\n",
        "\n",
        "# Split: 70% train, 15% validation, 15% test\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "print(f\"Total images: {total_size}\")\n",
        "print(f\"Train: {train_size}, Validation: {val_size}, Test: {test_size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize some samples from the dataset\n",
        "def show_samples(dataset, num_samples=4):\n",
        "    \"\"\"Display sample images with their masks.\"\"\"\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        idx = random.randint(0, len(dataset)-1)\n",
        "        image, mask = dataset[idx]\n",
        "        \n",
        "        # Convert tensors to numpy for display\n",
        "        img_np = image.permute(1, 2, 0).numpy()\n",
        "        mask_np = mask.squeeze().numpy()\n",
        "        \n",
        "        # Original image\n",
        "        axes[i, 0].imshow(img_np)\n",
        "        axes[i, 0].set_title('Original Image')\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        # Mask\n",
        "        axes[i, 1].imshow(mask_np, cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth Mask')\n",
        "        axes[i, 1].axis('off')\n",
        "        \n",
        "        # Overlay\n",
        "        axes[i, 2].imshow(img_np)\n",
        "        axes[i, 2].imshow(mask_np, alpha=0.5, cmap='Reds')\n",
        "        axes[i, 2].set_title('Overlay')\n",
        "        axes[i, 2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(full_dataset, num_samples=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. UNet Architecture\n",
        "\n",
        "UNet consists of:\n",
        "1. **Encoder (Contracting Path)**: Captures context through convolutions and pooling\n",
        "2. **Bottleneck**: Bridge between encoder and decoder\n",
        "3. **Decoder (Expanding Path)**: Enables precise localization through upsampling\n",
        "4. **Skip Connections**: Connect encoder to decoder to preserve spatial information\n",
        "\n",
        "Our implementation is configurable:\n",
        "- `depth`: Number of encoder/decoder blocks (2 for shallow, 4 for standard)\n",
        "- `use_skip`: Toggle skip connections on/off for experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Double convolution block: Conv -> BN -> ReLU -> Conv -> BN -> ReLU\n",
        "    \n",
        "    This is the basic building block of UNet.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder block: ConvBlock followed by MaxPool for downsampling.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv = ConvBlock(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x)      # Features to pass via skip connection\n",
        "        pooled = self.pool(conv_out)  # Downsampled for next encoder block\n",
        "        return conv_out, pooled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder block: Upsample -> Concatenate skip connection -> ConvBlock\n",
        "    \n",
        "    Args:\n",
        "        in_channels: Input channels (from previous decoder or bottleneck)\n",
        "        out_channels: Output channels\n",
        "        use_skip: If True, concatenate skip connection from encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, use_skip=True):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.use_skip = use_skip\n",
        "        \n",
        "        # Transposed convolution for upsampling\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        \n",
        "        # If using skip connections, input to conv is doubled\n",
        "        conv_in_channels = out_channels * 2 if use_skip else out_channels\n",
        "        self.conv = ConvBlock(conv_in_channels, out_channels)\n",
        "    \n",
        "    def forward(self, x, skip=None):\n",
        "        x = self.up(x)\n",
        "        \n",
        "        if self.use_skip and skip is not None:\n",
        "            # Concatenate skip connection along channel dimension\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "        \n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Configurable UNet for image segmentation.\n",
        "    \n",
        "    Args:\n",
        "        in_channels: Number of input channels (3 for RGB)\n",
        "        out_channels: Number of output channels (1 for binary segmentation)\n",
        "        depth: Number of encoder/decoder blocks (2=shallow, 4=standard)\n",
        "        base_features: Number of features in first layer (doubles each level)\n",
        "        use_skip: Whether to use skip connections\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=1, depth=4, \n",
        "                 base_features=64, use_skip=True):\n",
        "        super(UNet, self).__init__()\n",
        "        \n",
        "        self.depth = depth\n",
        "        self.use_skip = use_skip\n",
        "        \n",
        "        # Calculate feature sizes for each level\n",
        "        # e.g., depth=4: [64, 128, 256, 512] for encoder, 1024 for bottleneck\n",
        "        features = [base_features * (2**i) for i in range(depth)]\n",
        "        \n",
        "        # Encoder blocks\n",
        "        self.encoders = nn.ModuleList()\n",
        "        in_ch = in_channels\n",
        "        for feat in features:\n",
        "            self.encoders.append(EncoderBlock(in_ch, feat))\n",
        "            in_ch = feat\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.bottleneck = ConvBlock(features[-1], features[-1] * 2)\n",
        "        \n",
        "        # Decoder blocks (reverse order of features)\n",
        "        self.decoders = nn.ModuleList()\n",
        "        in_ch = features[-1] * 2\n",
        "        for feat in reversed(features):\n",
        "            self.decoders.append(DecoderBlock(in_ch, feat, use_skip=use_skip))\n",
        "            in_ch = feat\n",
        "        \n",
        "        # Final 1x1 convolution to get output channels\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Encoder path - save outputs for skip connections\n",
        "        skip_connections = []\n",
        "        for encoder in self.encoders:\n",
        "            skip, x = encoder(x)\n",
        "            skip_connections.append(skip)\n",
        "        \n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "        \n",
        "        # Decoder path - use skip connections in reverse order\n",
        "        skip_connections = skip_connections[::-1]  # Reverse\n",
        "        for i, decoder in enumerate(self.decoders):\n",
        "            skip = skip_connections[i] if self.use_skip else None\n",
        "            x = decoder(x, skip)\n",
        "        \n",
        "        # Final convolution + sigmoid for binary output\n",
        "        return torch.sigmoid(self.final_conv(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test UNet architecture\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count trainable parameters in a model.\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Test different configurations\n",
        "print(\"UNet Architecture Configurations:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for depth in [2, 4]:\n",
        "    for use_skip in [True, False]:\n",
        "        model = UNet(depth=depth, use_skip=use_skip)\n",
        "        params = count_parameters(model)\n",
        "        skip_str = \"with skip\" if use_skip else \"no skip\"\n",
        "        print(f\"Depth={depth}, {skip_str}: {params:,} parameters\")\n",
        "\n",
        "# Verify forward pass works\n",
        "model = UNet(depth=4, use_skip=True)\n",
        "test_input = torch.randn(1, 3, 256, 256)\n",
        "test_output = model(test_input)\n",
        "print(f\"\\nInput shape: {test_input.shape}\")\n",
        "print(f\"Output shape: {test_output.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Loss Functions\n",
        "\n",
        "We implement three loss functions for comparison:\n",
        "\n",
        "1. **BCE (Binary Cross-Entropy)**: Standard classification loss, treats each pixel independently\n",
        "2. **Dice Loss**: Measures overlap between prediction and ground truth, better for imbalanced data\n",
        "3. **Combined Loss**: BCE + Dice, combines benefits of both\n",
        "\n",
        "**Dice Coefficient Formula**:\n",
        "$$Dice = \\frac{2 \\times |A \\cap B|}{|A| + |B|}$$\n",
        "\n",
        "Where A is the predicted mask and B is the ground truth mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Dice Loss for segmentation.\n",
        "    \n",
        "    Dice = 2 * intersection / (sum of both areas)\n",
        "    Loss = 1 - Dice\n",
        "    \"\"\"\n",
        "    def __init__(self, smooth=1e-5):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        # Flatten predictions and targets\n",
        "        pred_flat = pred.view(-1)\n",
        "        target_flat = target.view(-1)\n",
        "        \n",
        "        # Calculate intersection and union\n",
        "        intersection = (pred_flat * target_flat).sum()\n",
        "        union = pred_flat.sum() + target_flat.sum()\n",
        "        \n",
        "        # Dice coefficient\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "        \n",
        "        return 1.0 - dice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class BCEDiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined BCE and Dice Loss.\n",
        "    \n",
        "    Combines the pixel-wise accuracy of BCE with the \n",
        "    region-based overlap measurement of Dice.\n",
        "    \"\"\"\n",
        "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.bce = nn.BCELoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        bce_loss = self.bce(pred, target)\n",
        "        dice_loss = self.dice(pred, target)\n",
        "        return self.bce_weight * bce_loss + self.dice_weight * dice_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Loss function factory\n",
        "def get_loss_function(loss_type='combined'):\n",
        "    \"\"\"\n",
        "    Get loss function by name.\n",
        "    \n",
        "    Args:\n",
        "        loss_type: 'bce', 'dice', or 'combined'\n",
        "    \"\"\"\n",
        "    if loss_type == 'bce':\n",
        "        return nn.BCELoss()\n",
        "    elif loss_type == 'dice':\n",
        "        return DiceLoss()\n",
        "    elif loss_type == 'combined':\n",
        "        return BCEDiceLoss()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown loss type: {loss_type}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluation Metrics\n",
        "\n",
        "We use standard segmentation metrics:\n",
        "- **Dice Coefficient**: Primary metric, measures overlap (higher is better)\n",
        "- **IoU (Intersection over Union)**: Also called Jaccard Index\n",
        "- **Precision**: True positives / (True positives + False positives)\n",
        "- **Recall**: True positives / (True positives + False negatives)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def calculate_metrics(pred, target, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate segmentation metrics.\n",
        "    \n",
        "    Args:\n",
        "        pred: Predicted mask (probabilities)\n",
        "        target: Ground truth mask\n",
        "        threshold: Threshold for binarizing predictions\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with dice, iou, precision, recall\n",
        "    \"\"\"\n",
        "    # Binarize predictions\n",
        "    pred_binary = (pred > threshold).float()\n",
        "    \n",
        "    # Flatten\n",
        "    pred_flat = pred_binary.view(-1)\n",
        "    target_flat = target.view(-1)\n",
        "    \n",
        "    # True positives, false positives, false negatives\n",
        "    tp = (pred_flat * target_flat).sum()\n",
        "    fp = (pred_flat * (1 - target_flat)).sum()\n",
        "    fn = ((1 - pred_flat) * target_flat).sum()\n",
        "    \n",
        "    # Metrics\n",
        "    smooth = 1e-5\n",
        "    \n",
        "    # Dice coefficient\n",
        "    dice = (2 * tp + smooth) / (2 * tp + fp + fn + smooth)\n",
        "    \n",
        "    # IoU (Jaccard)\n",
        "    iou = (tp + smooth) / (tp + fp + fn + smooth)\n",
        "    \n",
        "    # Precision and Recall\n",
        "    precision = (tp + smooth) / (tp + fp + smooth)\n",
        "    recall = (tp + smooth) / (tp + fn + smooth)\n",
        "    \n",
        "    return {\n",
        "        'dice': dice.item(),\n",
        "        'iou': iou.item(),\n",
        "        'precision': precision.item(),\n",
        "        'recall': recall.item()\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Loop\n",
        "\n",
        "The training loop includes:\n",
        "- Training and validation phases\n",
        "- Early stopping to prevent overfitting\n",
        "- Learning rate scheduling\n",
        "- Metric logging for analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_dice = 0\n",
        "    \n",
        "    for images, masks in dataloader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Track metrics\n",
        "        total_loss += loss.item()\n",
        "        metrics = calculate_metrics(outputs, masks)\n",
        "        total_dice += metrics['dice']\n",
        "    \n",
        "    n_batches = len(dataloader)\n",
        "    return total_loss / n_batches, total_dice / n_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@torch.no_grad()\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate the model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_metrics = {'dice': 0, 'iou': 0, 'precision': 0, 'recall': 0}\n",
        "    \n",
        "    for images, masks in dataloader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        metrics = calculate_metrics(outputs, masks)\n",
        "        for key in all_metrics:\n",
        "            all_metrics[key] += metrics[key]\n",
        "    \n",
        "    n_batches = len(dataloader)\n",
        "    avg_loss = total_loss / n_batches\n",
        "    avg_metrics = {k: v / n_batches for k, v in all_metrics.items()}\n",
        "    \n",
        "    return avg_loss, avg_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
        "                scheduler, device, num_epochs=50, patience=10):\n",
        "    \"\"\"\n",
        "    Full training loop with early stopping.\n",
        "    \n",
        "    Args:\n",
        "        model: UNet model\n",
        "        train_loader: Training data loader\n",
        "        val_loader: Validation data loader\n",
        "        criterion: Loss function\n",
        "        optimizer: Optimizer\n",
        "        scheduler: Learning rate scheduler\n",
        "        device: Device to train on\n",
        "        num_epochs: Maximum number of epochs\n",
        "        patience: Early stopping patience\n",
        "    \n",
        "    Returns:\n",
        "        history: Dictionary with training history\n",
        "        best_model_state: State dict of best model\n",
        "    \"\"\"\n",
        "    history = {\n",
        "        'train_loss': [], 'train_dice': [],\n",
        "        'val_loss': [], 'val_dice': [], 'val_iou': []\n",
        "    }\n",
        "    \n",
        "    best_val_dice = 0\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        train_loss, train_dice = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, device\n",
        "        )\n",
        "        \n",
        "        # Validation\n",
        "        val_loss, val_metrics = validate(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        # Log history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_dice'].append(train_dice)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_dice'].append(val_metrics['dice'])\n",
        "        history['val_iou'].append(val_metrics['iou'])\n",
        "        \n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Dice: {train_dice:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Dice: {val_metrics['dice']:.4f}\")\n",
        "        \n",
        "        # Early stopping check\n",
        "        if val_metrics['dice'] > best_val_dice:\n",
        "            best_val_dice = val_metrics['dice']\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "    \n",
        "    return history, best_model_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Experiment Runner\n",
        "\n",
        "We define a function to run experiments with different configurations and store results for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_experiment(name, depth, use_skip, loss_type, train_loader, val_loader, \n",
        "                   device, num_epochs=50, lr=1e-4):\n",
        "    \"\"\"\n",
        "    Run a single experiment with given configuration.\n",
        "    \n",
        "    Args:\n",
        "        name: Experiment name for logging\n",
        "        depth: UNet depth (2 or 4)\n",
        "        use_skip: Whether to use skip connections\n",
        "        loss_type: 'bce', 'dice', or 'combined'\n",
        "        train_loader: Training data loader\n",
        "        val_loader: Validation data loader\n",
        "        device: Device to train on\n",
        "        num_epochs: Maximum epochs\n",
        "        lr: Learning rate\n",
        "    \n",
        "    Returns:\n",
        "        results: Dictionary with experiment results\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Experiment: {name}\")\n",
        "    print(f\"Config: depth={depth}, skip={use_skip}, loss={loss_type}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    # Create model\n",
        "    model = UNet(depth=depth, use_skip=use_skip).to(device)\n",
        "    \n",
        "    # Loss function\n",
        "    criterion = get_loss_function(loss_type)\n",
        "    \n",
        "    # Optimizer and scheduler\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "    \n",
        "    # Train\n",
        "    history, best_state = train_model(\n",
        "        model, train_loader, val_loader, criterion, optimizer,\n",
        "        scheduler, device, num_epochs=num_epochs, patience=10\n",
        "    )\n",
        "    \n",
        "    # Load best model and evaluate on validation\n",
        "    model.load_state_dict(best_state)\n",
        "    val_loss, val_metrics = validate(model, val_loader, criterion, device)\n",
        "    \n",
        "    results = {\n",
        "        'name': name,\n",
        "        'depth': depth,\n",
        "        'use_skip': use_skip,\n",
        "        'loss_type': loss_type,\n",
        "        'history': history,\n",
        "        'best_model_state': best_state,\n",
        "        'final_metrics': val_metrics\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nBest Validation Results for {name}:\")\n",
        "    print(f\"  Dice: {val_metrics['dice']:.4f}\")\n",
        "    print(f\"  IoU:  {val_metrics['iou']:.4f}\")\n",
        "    \n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create data loaders with augmentation for training\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Training dataset with augmentation\n",
        "train_dataset_aug = PolypDataset(IMAGE_DIR, MASK_DIR, img_size=256, augment=True)\n",
        "train_indices = train_dataset.indices  # Get indices from the split\n",
        "train_subset_aug = torch.utils.data.Subset(train_dataset_aug, train_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Run All Experiments\n",
        "\n",
        "We run 5 experiments to compare:\n",
        "1. **Shallow UNet** (depth=2) vs **Standard UNet** (depth=4) - Effect of depth\n",
        "2. **UNet WITHOUT skip connections** - Ablation study\n",
        "3. **Different loss functions** - BCE vs Dice vs Combined\n",
        "\n",
        "Note: Exp2 (Standard UNet) serves as the baseline for multiple comparisons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define experiment configurations (streamlined - removed redundant experiments)\n",
        "experiments_config = [\n",
        "    # Experiment 1: Shallow UNet (for depth comparison)\n",
        "    {'name': 'Exp1_Shallow_UNet', 'depth': 2, 'use_skip': True, 'loss_type': 'combined'},\n",
        "    \n",
        "    # Experiment 2: Standard UNet (baseline for all comparisons)\n",
        "    {'name': 'Exp2_Standard_UNet', 'depth': 4, 'use_skip': True, 'loss_type': 'combined'},\n",
        "    \n",
        "    # Experiment 3: UNet WITHOUT skip connections (for skip connection ablation)\n",
        "    {'name': 'Exp3_NoSkip', 'depth': 4, 'use_skip': False, 'loss_type': 'combined'},\n",
        "    \n",
        "    # Experiment 4: BCE Loss only (for loss function comparison)\n",
        "    {'name': 'Exp4_BCE_Loss', 'depth': 4, 'use_skip': True, 'loss_type': 'bce'},\n",
        "    \n",
        "    # Experiment 5: Dice Loss only (for loss function comparison)\n",
        "    {'name': 'Exp5_Dice_Loss', 'depth': 4, 'use_skip': True, 'loss_type': 'dice'},\n",
        "]\n",
        "\n",
        "print(\"Experiments to run:\")\n",
        "for i, exp in enumerate(experiments_config, 1):\n",
        "    print(f\"  {i}. {exp['name']}: depth={exp['depth']}, skip={exp['use_skip']}, loss={exp['loss_type']}\")\n",
        "\n",
        "print(\"\\nComparisons:\")\n",
        "print(\"  - Depth effect: Exp1 vs Exp2\")\n",
        "print(\"  - Skip connections: Exp3 vs Exp2\")\n",
        "print(\"  - Loss functions: Exp4 vs Exp5 vs Exp2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run all experiments (this will take some time)\n",
        "# Reduce epochs for faster experimentation, increase for better results\n",
        "NUM_EPOCHS = 30  # Increase to 50 for final results\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for config in experiments_config:\n",
        "    results = run_experiment(\n",
        "        name=config['name'],\n",
        "        depth=config['depth'],\n",
        "        use_skip=config['use_skip'],\n",
        "        loss_type=config['loss_type'],\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        device=device,\n",
        "        num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "    all_results[config['name']] = results\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALL EXPERIMENTS COMPLETED!\")\n",
        "print(\"=\"*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Results Visualization\n",
        "\n",
        "### 10.1 Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create summary table of all experiments\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENT RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Experiment':<25} {'Depth':<8} {'Skip':<8} {'Loss':<12} {'Dice':<10} {'IoU':<10}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for name, results in all_results.items():\n",
        "    metrics = results['final_metrics']\n",
        "    print(f\"{name:<25} {results['depth']:<8} {str(results['use_skip']):<8} \"\n",
        "          f\"{results['loss_type']:<12} {metrics['dice']:.4f}     {metrics['iou']:.4f}\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.2 Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_training_curves(results_dict, experiments_to_plot):\n",
        "    \"\"\"Plot training curves for selected experiments.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    for exp_name in experiments_to_plot:\n",
        "        if exp_name in results_dict:\n",
        "            history = results_dict[exp_name]['history']\n",
        "            epochs = range(1, len(history['train_loss']) + 1)\n",
        "            \n",
        "            # Loss curves\n",
        "            axes[0].plot(epochs, history['train_loss'], '--', label=f'{exp_name} (train)')\n",
        "            axes[0].plot(epochs, history['val_loss'], '-', label=f'{exp_name} (val)')\n",
        "            \n",
        "            # Dice curves\n",
        "            axes[1].plot(epochs, history['val_dice'], '-', label=exp_name)\n",
        "    \n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend(loc='upper right', fontsize=8)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Dice Coefficient')\n",
        "    axes[1].set_title('Validation Dice Coefficient')\n",
        "    axes[1].legend(loc='lower right', fontsize=8)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot 1: Shallow vs Standard UNet\n",
        "print(\"Comparison 1: Shallow vs Standard UNet (Effect of Depth)\")\n",
        "plot_training_curves(all_results, ['Exp1_Shallow_UNet', 'Exp2_Standard_UNet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot 2: With vs Without Skip Connections\n",
        "print(\"Comparison 2: Effect of Skip Connections\")\n",
        "plot_training_curves(all_results, ['Exp3_NoSkip', 'Exp2_Standard_UNet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot 3: Different Loss Functions\n",
        "print(\"Comparison 3: Effect of Different Loss Functions\")\n",
        "plot_training_curves(all_results, ['Exp4_BCE_Loss', 'Exp5_Dice_Loss', 'Exp2_Standard_UNet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.3 Bar Chart Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_metrics_comparison(results_dict):\n",
        "    \"\"\"Create bar chart comparing all experiments.\"\"\"\n",
        "    names = list(results_dict.keys())\n",
        "    dice_scores = [results_dict[n]['final_metrics']['dice'] for n in names]\n",
        "    iou_scores = [results_dict[n]['final_metrics']['iou'] for n in names]\n",
        "    \n",
        "    x = np.arange(len(names))\n",
        "    width = 0.35\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    bars1 = ax.bar(x - width/2, dice_scores, width, label='Dice', color='steelblue')\n",
        "    bars2 = ax.bar(x + width/2, iou_scores, width, label='IoU', color='coral')\n",
        "    \n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Comparison of All Experiments')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([n.replace('_', '\\n') for n in names], fontsize=8)\n",
        "    ax.legend()\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar in bars1:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=7)\n",
        "    for bar in bars2:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=7)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_metrics_comparison(all_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.4 Prediction Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@torch.no_grad()\n",
        "def visualize_predictions(model, dataset, device, num_samples=4, title=\"Predictions\"):\n",
        "    \"\"\"Visualize model predictions on sample images.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
        "    \n",
        "    indices = random.sample(range(len(dataset)), num_samples)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        image, mask = dataset[idx]\n",
        "        \n",
        "        # Get prediction\n",
        "        image_batch = image.unsqueeze(0).to(device)\n",
        "        pred = model(image_batch).squeeze().cpu()\n",
        "        pred_binary = (pred > 0.5).float()\n",
        "        \n",
        "        # Convert to numpy\n",
        "        img_np = image.permute(1, 2, 0).numpy()\n",
        "        mask_np = mask.squeeze().numpy()\n",
        "        pred_np = pred.numpy()\n",
        "        pred_bin_np = pred_binary.numpy()\n",
        "        \n",
        "        # Plot\n",
        "        axes[i, 0].imshow(img_np)\n",
        "        axes[i, 0].set_title('Input Image')\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        axes[i, 1].imshow(mask_np, cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth')\n",
        "        axes[i, 1].axis('off')\n",
        "        \n",
        "        axes[i, 2].imshow(pred_np, cmap='gray')\n",
        "        axes[i, 2].set_title('Prediction (Raw)')\n",
        "        axes[i, 2].axis('off')\n",
        "        \n",
        "        # Overlay\n",
        "        axes[i, 3].imshow(img_np)\n",
        "        axes[i, 3].imshow(pred_bin_np, alpha=0.5, cmap='Reds')\n",
        "        axes[i, 3].set_title('Overlay')\n",
        "        axes[i, 3].axis('off')\n",
        "    \n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize predictions from best model (Standard UNet with skip connections)\n",
        "best_exp = 'Exp2_Standard_UNet'\n",
        "best_model = UNet(depth=4, use_skip=True).to(device)\n",
        "best_model.load_state_dict(all_results[best_exp]['best_model_state'])\n",
        "\n",
        "print(f\"Predictions from: {best_exp}\")\n",
        "visualize_predictions(best_model, test_dataset, device, num_samples=4, \n",
        "                      title=f\"Predictions - {best_exp}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10.5 Compare Skip vs No-Skip Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@torch.no_grad()\n",
        "def compare_skip_vs_noskip(results_dict, dataset, device, num_samples=3):\n",
        "    \"\"\"Compare predictions with and without skip connections.\"\"\"\n",
        "    # Load models\n",
        "    model_skip = UNet(depth=4, use_skip=True).to(device)\n",
        "    model_skip.load_state_dict(results_dict['Exp2_Standard_UNet']['best_model_state'])\n",
        "    model_skip.eval()\n",
        "    \n",
        "    model_noskip = UNet(depth=4, use_skip=False).to(device)\n",
        "    model_noskip.load_state_dict(results_dict['Exp3_NoSkip']['best_model_state'])\n",
        "    model_noskip.eval()\n",
        "    \n",
        "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
        "    \n",
        "    indices = random.sample(range(len(dataset)), num_samples)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        image, mask = dataset[idx]\n",
        "        image_batch = image.unsqueeze(0).to(device)\n",
        "        \n",
        "        # Get predictions\n",
        "        pred_skip = model_skip(image_batch).squeeze().cpu()\n",
        "        pred_noskip = model_noskip(image_batch).squeeze().cpu()\n",
        "        \n",
        "        # Convert to numpy\n",
        "        img_np = image.permute(1, 2, 0).numpy()\n",
        "        mask_np = mask.squeeze().numpy()\n",
        "        \n",
        "        # Plot\n",
        "        axes[i, 0].imshow(img_np)\n",
        "        axes[i, 0].set_title('Input Image')\n",
        "        axes[i, 0].axis('off')\n",
        "        \n",
        "        axes[i, 1].imshow(mask_np, cmap='gray')\n",
        "        axes[i, 1].set_title('Ground Truth')\n",
        "        axes[i, 1].axis('off')\n",
        "        \n",
        "        axes[i, 2].imshow((pred_noskip > 0.5).numpy(), cmap='gray')\n",
        "        axes[i, 2].set_title('WITHOUT Skip Connections')\n",
        "        axes[i, 2].axis('off')\n",
        "        \n",
        "        axes[i, 3].imshow((pred_skip > 0.5).numpy(), cmap='gray')\n",
        "        axes[i, 3].set_title('WITH Skip Connections')\n",
        "        axes[i, 3].axis('off')\n",
        "    \n",
        "    plt.suptitle('Effect of Skip Connections on Segmentation Quality', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "compare_skip_vs_noskip(all_results, test_dataset, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Test Set Evaluation\n",
        "\n",
        "Final evaluation on the held-out test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate best model on test set\n",
        "print(\"=\"*60)\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Use the best performing model\n",
        "best_model = UNet(depth=4, use_skip=True).to(device)\n",
        "best_model.load_state_dict(all_results['Exp2_Standard_UNet']['best_model_state'])\n",
        "\n",
        "criterion = BCEDiceLoss()\n",
        "test_loss, test_metrics = validate(best_model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"\\nTest Set Results (Standard UNet with Skip Connections):\")\n",
        "print(f\"  Loss:      {test_loss:.4f}\")\n",
        "print(f\"  Dice:      {test_metrics['dice']:.4f}\")\n",
        "print(f\"  IoU:       {test_metrics['iou']:.4f}\")\n",
        "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
        "print(f\"  Recall:    {test_metrics['recall']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Analysis and Conclusions\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "1. **Effect of Depth**: Standard UNet (4 blocks) outperforms Shallow UNet (2 blocks), demonstrating that deeper architectures can capture more complex features.\n",
        "\n",
        "2. **Importance of Skip Connections**: UNet WITH skip connections significantly outperforms UNet WITHOUT skip connections. This confirms that skip connections are crucial for preserving spatial information during upsampling.\n",
        "\n",
        "3. **Loss Function Comparison**: Combined loss (BCE + Dice) generally performs best, as it combines pixel-wise accuracy with region-based overlap optimization.\n",
        "\n",
        "### Why Skip Connections Matter:\n",
        "- During encoding, spatial information is lost due to pooling\n",
        "- Skip connections directly transfer high-resolution features from encoder to decoder\n",
        "- This helps the decoder produce sharper, more accurate boundaries\n",
        "- Without skip connections, the model struggles to localize polyp boundaries precisely\n",
        "\n",
        "### Clinical Implications:\n",
        "- Accurate polyp segmentation can assist gastroenterologists during colonoscopy\n",
        "- Better boundary detection helps in assessing polyp size and morphology\n",
        "- Automated systems can serve as a \"second pair of eyes\" to reduce miss rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Future Work\n",
        "\n",
        "Potential extensions of this work:\n",
        "\n",
        "1. **Attention Mechanisms**: Add attention gates to skip connections (Attention U-Net)\n",
        "2. **Different Backbones**: Use pre-trained encoders (ResNet, EfficientNet)\n",
        "3. **Multi-scale Features**: Implement Feature Pyramid Networks\n",
        "4. **Data Augmentation**: More aggressive augmentation (elastic deformation, color jittering)\n",
        "5. **Post-processing**: Conditional Random Fields (CRF) for boundary refinement\n",
        "6. **Real-time Inference**: Optimize for deployment in clinical settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Save Models (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save best model\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "for exp_name, results in all_results.items():\n",
        "    save_path = f'saved_models/{exp_name}.pth'\n",
        "    torch.save(results['best_model_state'], save_path)\n",
        "    print(f\"Saved: {save_path}\")\n",
        "\n",
        "print(\"\\nAll models saved!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "1. Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. MICCAI.\n",
        "\n",
        "2. Jha, D., et al. (2020). Kvasir-SEG: A Segmented Polyp Dataset. MMM 2020.\n",
        "\n",
        "3. Jha, D., et al. (2020). Automatic Polyp Segmentation using U-Net-ResNet50. arXiv:2012.15247.\n",
        "\n",
        "4. Huang, C.H., et al. (2021). HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network. arXiv:2101.07172.\n",
        "\n",
        "5. Dataset: https://datasets.simula.no/kvasir-seg/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}